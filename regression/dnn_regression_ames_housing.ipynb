{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../utils')\n",
    "from load_data import ames_housing\n",
    "from preprocess_data import cat2int\n",
    "\n",
    "import functools\n",
    "import tensorflow as tf\n",
    "#from tensorflow.python.feature_column.feature_column import _LazyBuilder\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../utils/load_data.py:202: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  testdf_new['Id'] = test_ID\n"
     ]
    }
   ],
   "source": [
    "dirfolder = '../data/Ames-Housing'\n",
    "numvalid = 100\n",
    "train, valid, testdf = ames_housing(dirfolder, numvalid)\n",
    "traindf, trainy = train\n",
    "validdf, validy = valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocess input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = traindf.values\n",
    "validdata = validdf.values\n",
    "testdata = testdf.values\n",
    "\n",
    "# normalization\n",
    "max_val = np.max(traindata, axis=0)\n",
    "min_val = np.min(traindata, axis=0)\n",
    "for i in range(traindata.shape[1]):\n",
    "    if max_val[i] != 0:\n",
    "        traindata[:, i] = (traindata[:, i]-min_val[i])/(max_val[i]-min_val[i])\n",
    "        validdata[:, i] = (validdata[:, i]-min_val[i])/(max_val[i]-min_val[i])\n",
    "        testdata[:, i] = (testdata[:, i]-min_val[i])/(max_val[i]-min_val[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create dataflow graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "lr_decay = 1.0\n",
    "lr_0 = 1.0\n",
    "batch_size = 32\n",
    "iterations = 500000\n",
    "monitor = 10000\n",
    "perf_reduce = 0.3\n",
    "keep_prob_input_0 = 0.8\n",
    "keep_prob_a_0 = 0.5\n",
    "\n",
    "# network size\n",
    "num_train, num_in = traindata.shape\n",
    "num_hidden_1 = 100\n",
    "num_hidden_2 = 50\n",
    "num_hidden_3 = 25\n",
    "num_out = 1\n",
    "\n",
    "# create network graph\n",
    "## input and hidden layer 1\n",
    "x = tf.placeholder(tf.float32, [None, num_in])\n",
    "keep_prob_input = tf.placeholder(tf.float32)\n",
    "keep_prob_a = tf.placeholder(tf.float32)\n",
    "x_drop = tf.nn.dropout(x, keep_prob_input)\n",
    "W_1 = tf.Variable(tf.random_normal([num_in, num_hidden_1], stddev=0.1))\n",
    "b_1 = tf.Variable(tf.random_normal([num_hidden_1], stddev=0.1))\n",
    "y_1 = tf.matmul(x_drop, W_1) + b_1\n",
    "a_1 = tf.nn.selu(y_1)\n",
    "bn_a_1 = tf.layers.batch_normalization(a_1)\n",
    "a_1_drop = tf.nn.dropout(bn_a_1, keep_prob_a)\n",
    "\n",
    "## hidden layer 1 and 2\n",
    "W_2 = tf.Variable(tf.random_normal([num_hidden_1, num_hidden_2], stddev=0.1))\n",
    "b_2 = tf.Variable(tf.random_normal([num_hidden_2], stddev=0.1))\n",
    "y_2 = tf.matmul(a_1_drop, W_2) + b_2\n",
    "a_2 = tf.nn.selu(y_2)\n",
    "bn_a_2 = tf.layers.batch_normalization(a_2)\n",
    "a_2_drop = tf.nn.dropout(bn_a_2, keep_prob_a)\n",
    "\n",
    "## hidden layer 2 and 3\n",
    "W_3 = tf.Variable(tf.random_normal([num_hidden_2, num_hidden_3], stddev=0.1))\n",
    "b_3 = tf.Variable(tf.random_normal([num_hidden_3], stddev=0.1))\n",
    "y_3 = tf.matmul(a_2_drop, W_3) + b_3\n",
    "a_3 = tf.nn.selu(y_3)\n",
    "bn_a_3 = tf.layers.batch_normalization(a_3)\n",
    "a_3_drop = tf.nn.dropout(bn_a_3, keep_prob_a)\n",
    "\n",
    "## hidden layer 3 and output \n",
    "W_4 = tf.Variable(tf.random_normal([num_hidden_3, num_out], stddev=0.1))\n",
    "b_4 = tf.Variable(tf.random_normal([num_out], stddev=0.1))\n",
    "y_out = tf.matmul(a_3_drop, W_4) + b_4\n",
    "\n",
    "# create training graph\n",
    "learning_rate = tf.placeholder(tf.float32)\n",
    "y_ = tf.placeholder(tf.float32, [None, num_out])\n",
    "cost = tf.losses.mean_squared_error(y_, y_out)\n",
    "train = tf.train.AdadeltaOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model has been saved.\n",
      "0: 137.41915893554688, 136.74462890625\n",
      "Better model has been saved.\n",
      "10000: 0.1967027485370636, 0.18853135406970978\n",
      "Better model has been saved.\n",
      "20000: 0.0823640450835228, 0.07588567584753036\n",
      "Better model has been saved.\n",
      "30000: 0.07029766589403152, 0.06608142703771591\n",
      "Better model has been saved.\n",
      "40000: 0.038593754172325134, 0.03779486194252968\n",
      "Better model has been saved.\n",
      "50000: 0.01817265711724758, 0.021625518798828125\n",
      "60000: 0.019349901005625725, 0.02414541319012642\n",
      "Better model has been saved.\n",
      "70000: 0.014460388571023941, 0.020654449239373207\n",
      "80000: 0.013785775750875473, 0.02085169404745102\n",
      "90000: 0.013292822055518627, 0.02122700773179531\n",
      "100000: 0.013471725396811962, 0.02119981311261654\n",
      "110000: 0.013298382051289082, 0.021411821246147156\n",
      "120000: 0.01412172894924879, 0.022094642743468285\n",
      "130000: 0.013055992312729359, 0.020729275420308113\n",
      "Better model has been saved.\n",
      "140000: 0.011763963848352432, 0.019622011110186577\n",
      "150000: 0.012140484526753426, 0.020964231342077255\n",
      "160000: 0.011175261810421944, 0.019675683230161667\n",
      "170000: 0.01252599898725748, 0.020659802481532097\n",
      "180000: 0.011734829284250736, 0.019630305469036102\n",
      "Better model has been saved.\n",
      "190000: 0.01146572083234787, 0.019420327618718147\n",
      "200000: 0.011042315512895584, 0.019701188430190086\n",
      "210000: 0.01124009769409895, 0.02014135755598545\n",
      "220000: 0.012979517690837383, 0.022086484357714653\n",
      "230000: 0.01240747794508934, 0.02189168706536293\n",
      "240000: 0.011528486385941505, 0.020771117880940437\n",
      "Better model has been saved.\n",
      "250000: 0.01003214344382286, 0.01933024264872074\n",
      "260000: 0.010076409205794334, 0.019542444497346878\n",
      "Better model has been saved.\n",
      "270000: 0.009664551354944706, 0.019144006073474884\n",
      "280000: 0.009936286136507988, 0.01938675157725811\n",
      "290000: 0.009498081170022488, 0.019852736964821815\n",
      "300000: 0.009142345748841763, 0.019331209361553192\n",
      "310000: 0.011329553090035915, 0.021485337987542152\n",
      "320000: 0.009002150036394596, 0.0194107573479414\n",
      "330000: 0.009455300867557526, 0.019806476309895515\n",
      "340000: 0.010080677457153797, 0.02050185762345791\n",
      "350000: 0.01009370293468237, 0.01997108943760395\n",
      "360000: 0.010551090352237225, 0.02005627565085888\n",
      "370000: 0.00922441016882658, 0.019397541880607605\n",
      "380000: 0.009269420057535172, 0.019515937194228172\n",
      "390000: 0.00873639341443777, 0.019452309235930443\n",
      "400000: 0.00877011101692915, 0.0193727258592844\n",
      "410000: 0.00895124301314354, 0.019295675680041313\n",
      "420000: 0.009276950731873512, 0.020366515964269638\n",
      "430000: 0.008705844171345234, 0.01951340213418007\n",
      "440000: 0.009502923116087914, 0.020829200744628906\n",
      "450000: 0.00862708780914545, 0.020166419446468353\n",
      "Better model has been saved.\n",
      "460000: 0.008197879418730736, 0.01887449063360691\n",
      "470000: 0.008290629833936691, 0.0196395181119442\n",
      "480000: 0.008854434825479984, 0.01939490996301174\n",
      "490000: 0.00974712148308754, 0.020236773416399956\n"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "# train\n",
    "start = 0\n",
    "last_perf_train = np.inf\n",
    "last_perf_valid = np.inf\n",
    "best_perf_valid = np.inf\n",
    "saver = tf.train.Saver()\n",
    "for i in range(iterations):\n",
    "    session.run(train, feed_dict={x: traindata[start:start+batch_size, :], \n",
    "                                  y_: trainy[start:start+batch_size],\n",
    "                                  keep_prob_input: keep_prob_input_0,\n",
    "                                  keep_prob_a: keep_prob_a_0, \n",
    "                                  learning_rate: lr_0})\n",
    "    start += batch_size\n",
    "    if start > num_train-batch_size: \n",
    "        start = 0\n",
    "    if i % monitor == 0:\n",
    "        perf_train = session.run(cost, feed_dict={x: traindata, \n",
    "                                                  y_: trainy,\n",
    "                                                  keep_prob_input: 1.0,\n",
    "                                                  keep_prob_a: 1.0})\n",
    "        perf_valid = session.run(cost, feed_dict={x: validdata, \n",
    "                                                  y_: validy,\n",
    "                                                  keep_prob_input: 1.0,\n",
    "                                                  keep_prob_a: 1.0})\n",
    "        if (best_perf_valid != np.inf) and ((perf_valid-best_perf_valid)/best_perf_valid > perf_reduce):\n",
    "            print(\"Difference between two consercutive costs is too small.\")\n",
    "            break\n",
    "        last_perf_train = perf_train\n",
    "        last_perf_valid = perf_valid\n",
    "        if perf_valid < best_perf_valid:\n",
    "            save_path = saver.save(session, \"model/dnnreg_model.ckpt\")\n",
    "            print(\"Better model has been saved.\")\n",
    "            best_perf_valid = perf_valid\n",
    "        lr_0 = lr_0*lr_decay\n",
    "        print(\"{}: {}, {}\".format(i, perf_train, perf_valid))\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "saver.restore(session, 'model/dnnreg_model.ckpt')\n",
    "perf_train = session.run(cost, feed_dict={x: traindata, \n",
    "                                          y_: trainy,\n",
    "                                          keep_prob_input: 1.0,\n",
    "                                          keep_prob_a: 1.0})\n",
    "perf_valid = session.run(cost, feed_dict={x: validdata, \n",
    "                                          y_: validy,\n",
    "                                          keep_prob_input: 1.0,\n",
    "                                          keep_prob_a: 1.0})\n",
    "print(perf_train, perf_valid)\n",
    "predtrainy = session.run(y_out, feed_dict={x: traindata, \n",
    "                                           keep_prob_input: 1.0,\n",
    "                                           keep_prob_a: 1.0})\n",
    "predvalidy = session.run(y_out, feed_dict={x: validdata, \n",
    "                                           keep_prob_input: 1.0,\n",
    "                                           keep_prob_a: 1.0})\n",
    "predtesty = session.run(y_out, feed_dict={x: testdata, \n",
    "                                           keep_prob_input: 1.0,\n",
    "                                           keep_prob_a: 1.0})\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.expm1(trainy), label='True')\n",
    "ax.plot(np.expm1(predtrainy), label='Predict')\n",
    "ax.set_xlabel('Train Id')\n",
    "ax.set_ylabel('Sale Price')\n",
    "ax.set_title('Training result');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.expm1(validy), label='True')\n",
    "ax.plot(np.expm1(predvalidy), label='Predict')\n",
    "ax.set_xlabel('Valid Id')\n",
    "ax.set_ylabel('Sale Price')\n",
    "ax.set_title('Validation result');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save testing result for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_dict = {'Id': testdf.index.tolist(), 'SalePrice': np.expm1(predtesty).flatten()}\n",
    "dnnreg_submission = pd.DataFrame(sub_dict)\n",
    "dnnreg_submission.set_index('Id', inplace=True)\n",
    "dnnreg_submission.to_csv('dnnreg_submission')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
