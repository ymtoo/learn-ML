{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../utils')\n",
    "from load_data import ames_housing\n",
    "\n",
    "import functools\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.feature_column.feature_column import _LazyBuilder\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples is 1360.\n",
      "Number of valid samples is 100.\n",
      "Number of test samples is 1459.\n",
      "Number of feature columns is 79.\n",
      "Checking listnumeric ...\n",
      "[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
      "Checking dictcategorical ...\n",
      "[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ymtoo/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:5890: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "/home/ymtoo/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "dirfolder = '../data/Ames-Housing'\n",
    "numvalid = 100\n",
    "train, valid, testdf, listnumeric, dictcategorical = ames_housing(dirfolder, numvalid)\n",
    "traindf, trainy = train\n",
    "validdf, validy = valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting TensorFlow input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_column(listnumeric, dictcategorical):\n",
    "    listcategorical = list(dictcategorical.keys())\n",
    "    numeric_cols = []\n",
    "    for num in listnumeric:\n",
    "        numeric_cols.append(tf.feature_column.numeric_column(num))\n",
    "    categorical_cols = []\n",
    "    for cat in listcategorical:\n",
    "        cattemp = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "                cat, dictcategorical[cat])\n",
    "        categorical_cols.append(cattemp)\n",
    "    return numeric_cols, categorical_cols\n",
    "\n",
    "numeric_cols , categorical_cols = feature_column(listnumeric, dictcategorical)\n",
    "indicator_cols = list(map(tf.feature_column.indicator_column, categorical_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Regression using deep neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpfxxwduhd\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpfxxwduhd', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5715873048>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpfxxwduhd/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.72049e+12, step = 1\n",
      "INFO:tensorflow:global_step/sec: 34.9997\n",
      "INFO:tensorflow:loss = 2.10616e+11, step = 101 (2.858 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.8273\n",
      "INFO:tensorflow:loss = 1.16716e+11, step = 201 (2.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.487\n",
      "INFO:tensorflow:loss = 8.36585e+10, step = 301 (2.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.2816\n",
      "INFO:tensorflow:loss = 1.98215e+11, step = 401 (2.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.9198\n",
      "INFO:tensorflow:loss = 3.68236e+11, step = 501 (2.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.5355\n",
      "INFO:tensorflow:loss = 8.7931e+10, step = 601 (2.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 46.5473\n",
      "INFO:tensorflow:loss = 8.49068e+10, step = 701 (2.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.667\n",
      "INFO:tensorflow:loss = 5.26282e+10, step = 801 (2.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.6257\n",
      "INFO:tensorflow:loss = 1.18352e+11, step = 901 (2.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.0642\n",
      "INFO:tensorflow:loss = 6.34387e+10, step = 1001 (2.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.1012\n",
      "INFO:tensorflow:loss = 4.22401e+10, step = 1101 (2.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.1864\n",
      "INFO:tensorflow:loss = 6.85175e+10, step = 1201 (2.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 46.6726\n",
      "INFO:tensorflow:loss = 7.5487e+10, step = 1301 (2.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.1513\n",
      "INFO:tensorflow:loss = 6.35015e+10, step = 1401 (2.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.7743\n",
      "INFO:tensorflow:loss = 8.11061e+10, step = 1501 (2.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.2897\n",
      "INFO:tensorflow:loss = 6.66327e+10, step = 1601 (2.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.9968\n",
      "INFO:tensorflow:loss = 6.95627e+10, step = 1701 (2.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.7333\n",
      "INFO:tensorflow:loss = 8.91346e+10, step = 1801 (2.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 46.5281\n",
      "INFO:tensorflow:loss = 1.27837e+11, step = 1901 (2.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.6918\n",
      "INFO:tensorflow:loss = 4.57643e+10, step = 2001 (2.289 sec)\n"
     ]
    }
   ],
   "source": [
    "def easy_input_fn(df, label, num_epochs, shuffle, batch_size):\n",
    "    if label is None:\n",
    "        inputs = dict(df)\n",
    "    else:\n",
    "        inputs = (dict(df), label)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(inputs)\n",
    "    \n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(10000)\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "    return ds\n",
    "\n",
    "train_inpf =  functools.partial(easy_input_fn, \n",
    "                                traindf,\n",
    "                                label=trainy,  \n",
    "                                num_epochs=100, \n",
    "                                shuffle=True, \n",
    "                                batch_size=64)\n",
    "\n",
    "valid_inpf =  functools.partial(easy_input_fn, \n",
    "                                validdf, \n",
    "                                label=validy,\n",
    "                                num_epochs=1, \n",
    "                                shuffle=True, \n",
    "                                batch_size=64)\n",
    "\n",
    "test_inpf =  functools.partial(easy_input_fn, \n",
    "                               validdf, \n",
    "                               label=None,\n",
    "                               num_epochs=1, \n",
    "                               shuffle=True, \n",
    "                               batch_size=64)\n",
    "\n",
    "reg = tf.estimator.DNNRegressor(\n",
    "    feature_columns=numeric_cols+indicator_cols,\n",
    "    hidden_units=[1024, 512, 256],\n",
    "    optimizer=tf.train.ProximalAdagradOptimizer(\n",
    "      learning_rate=0.01,\n",
    "      l1_regularization_strength=0.001))\n",
    "reg.train(train_inpf)\n",
    "result = reg.evaluate(valid_inpf)\n",
    "\n",
    "for key,value in sorted(result.items()):\n",
    "    print('%s: %0.2f' % (key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = reg.predict(valid_inpf)\n",
    "validypred = np.zeros((validy.size))\n",
    "for i, p in enumerate(pred):\n",
    "    validypred[i] = p['predictions'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Plot result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(validy, label='actual')\n",
    "ax.plot(validypred, label='predict')\n",
    "ax.set_xlabel('Valid data index')\n",
    "ax.grid()\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
